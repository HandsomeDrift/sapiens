# Geo-Sapiens：基于 Sapiens 基础模型与多模态几何一致性的幼儿姿态估计合成到真实（Sim-to-Real）自适应框架

## 摘要

幼儿运动功能的早期评估是检测脑瘫（CP）及其他神经发育障碍的关键临床手段。传统的“全身运动评估”（General Movements Assessment, GMA）依赖于临床专家的主观判断，难以大规模普及。基于计算机视觉的自动化姿态估计技术虽然前景广阔，但面临着严峻的“数据匮乏”与“域漂移”双重挑战：大规模标记数据多为合成（如 MINI-RGBD），而真实世界数据（如 SyRIP）稀缺且标注困难。此外，现有的基础模型（Foundation Models）如 Meta 发布的 Sapiens，主要针对成人数据预训练，直接应用于具有独特人体测量学特征（如头身比例、肢体脂肪遮挡）的幼儿时，表现出显著的分布外（OOD）退化。

本报告提出了一种名为 **Geo-Sapiens** 的高创新性微调方案。该方案旨在弥合合成数据（MINI-RGBD）与真实数据（SyRIP）之间的鸿沟。不同于传统的对抗性域适应或伪标签方法，Geo-Sapiens 创新性地利用 Sapiens 模型固有的多任务能力，将其冻结的深度（Depth）和法线（Normal）估计头作为“几何批评家（Geometric Critics）”，在无监督的真实数据上构建物理约束。通过引入“多模态几何一致性（MMGC）”损失和“幼儿流形正则化”，本方案将 Sim-to-Real 问题从单纯的特征对齐转化为三维几何一致性优化问题，从而在无需大量真实标注的情况下，实现高保真、解剖学合理的幼儿 2D 姿态估计。

------

## 1. 引言：临床需求与技术瓶颈的交汇

### 1.1 神经发育监测的临床紧迫性

脑瘫是儿童期最常见的身体残疾，其早期诊断对于利用神经可塑性进行干预至关重要。医学界公认的“黄金标准”是针对 0 至 5 个月大婴儿的“全身运动评估”（GMA）。这一评估方法的核心在于识别“不安运动”（Fidgety Movements）——一种具有中等速度、变加速且沿肢体轴线伴随细微旋转的自发性运动。这类运动的缺失或异常往往是神经系统受损的早期信号 1。

然而，捕捉这些细微的运动特征对计算机视觉系统提出了极高的要求。与成人动作识别不同，幼儿的运动幅度小、频率高，且常伴随复杂的自遮挡（如蜷缩姿势）。更重要的是，现有的医疗资源无法支持专家对每个高危婴儿进行长时间的视频分析。因此，开发一种能够自动、精确捕捉幼儿肢体关键点的计算机视觉系统，不仅是技术上的挑战，更是公共卫生领域的迫切需求。

### 1.2 数据困境：合成与真实的鸿沟

在深度学习时代，数据即性能。然而，幼儿姿态估计领域面临着独特的“数据寒冬”。出于隐私保护和伦理考量，构建大规模、高质量标注的真实幼儿数据集极其困难。现有的解决方案主要依赖于合成数据，但也因此引入了显著的“合成到真实”（Sim-to-Real）域漂移问题。

- **MINI-RGBD 数据集（合成锚点）：** 该数据集包含 12,000 张通过 Skinned Multi-Infant Linear (SMIL) 模型生成的合成婴儿图像 3。虽然它提供了完美的 2D/3D 关节标注，但其纹理渲染较为平滑，缺乏真实世界中的光照噪声、运动模糊及复杂的背景干扰。模型若仅在此数据集上训练，在真实场景下的泛化能力会大幅下降，即所谓的“Sim-to-Real Gap” 2。
- **SyRIP 数据集（混合桥梁）：** 该数据集包含 1,000 张合成图像和约 700 张真实婴儿图像 4。虽然真实样本数量不足以支持从头训练深度网络，但它们代表了目标域（Target Domain）的真实分布。如何有效利用这少量真实数据进行无监督或半监督适应，是本报告的核心议题。

### 1.3 Sapiens 基础模型的机遇与挑战

2024年，Meta Reality Labs 发布的 **Sapiens** 模型彻底改变了以人为中心的视觉任务格局 4。Sapiens 是一个基于 Vision Transformer (ViT) 的基础模型家族，参数量从 0.3B 到 2B 不等，在 3 亿张人类图像上进行了自监督预训练（MAE）。

- **核心优势：** Sapiens 原生支持 1024×1024 的高分辨率推理，这对于捕捉幼儿细微的手指和脚趾运动至关重要。此外，它不仅在姿态估计上表现出色，还在深度估计和表面法线预测等任务上达到了 SOTA 水平 4。
- **核心挑战：** Sapiens 的预训练数据主要由成人组成。成人的头身比约为 1:7.5，而婴儿约为 1:4；成人的肢体肌肉线条分明，而婴儿的肢体因皮下脂肪堆积而呈现圆柱状，关节位置常被皮肤褶皱掩盖。这种显著的“解剖学漂移”（Anatomical Shift）意味着直接应用 Sapiens 会导致显著的误差。

本报告旨在设计一种高创新性的微调方案，既能继承 Sapiens 强大的视觉特征提取能力，又能通过几何约束克服从成人到婴儿、从合成到真实的双重跨越。

------

## 2. 文献综述与理论基础

### 2.1 人体姿态估计的演进：从 CNN 到 ViT

过去十年，2D 人体姿态估计（HPE）经历了从 DeepPose 到 Hourglass，再到 HRNet 的演变。这些基于卷积神经网络（CNN）的方法虽然在 COCO 等成人数据集上表现优异，但在处理长距离依赖和严重遮挡时往往力不从心。 Vision Transformer (ViT) 的引入，特别是 **ViTPose** 和现在的 **Sapiens**，通过自注意力机制（Self-Attention）有效捕捉了全局上下文信息，显著提升了模型对复杂姿态的鲁棒性 4。

Sapiens 的独特之处在于其预训练策略。采用掩码自编码器（MAE）在大规模无标签人类数据上进行预训练，使得编码器能够学习到极具泛化性的解剖学结构特征 4。其“编码器-解码器”架构允许针对特定任务（如姿态、深度、法线）快速微调轻量级头部，这为我们的多任务适应方案提供了架构基础。

### 2.2 域适应（Domain Adaptation）的前沿技术

在 Sim-to-Real 场景中，主流的域适应方法包括：

1. **对抗性对齐（Adversarial Alignment）：** 如 FiDIP 5 使用 GANs 来对齐源域和目标域的特征分布。然而，这类方法往往关注全局风格迁移，容易忽略局部几何结构的一致性，导致关键点漂移。
2. **伪标签与自训练（Pseudo-labeling & Self-training）：** 如 SHIFT 框架 4 采用 Mean-Teacher 架构，利用教师模型在目标域上的预测作为伪标签。虽然有效，但伪标签本身可能存在噪音，若缺乏物理约束，模型容易陷入“确认偏误”（Confirmation Bias）。
3. **几何一致性（Geometric Consistency）：** 近期的研究开始探索利用深度、光流或多视角的几何约束来指导无监督学习 6。例如，利用骨长不变性或表面法线一致性来剔除错误的姿态预测。

### 2.3 婴儿姿态估计的特异性挑战

婴儿姿态估计不仅仅是成人模型的缩小版。文献 1 和 3 指出，婴儿的运动模式具有高度的随机性和非线性。此外，婴儿常处于仰卧位（Supine），肢体与床单、衣物的纹理极其相似，且存在大量的自遮挡（如手放入口中）。传统的基于边缘检测或纹理特征的方法极易失效。Sapiens 的高分辨率和对表面法线的敏感性为解决这一问题提供了新的切入点——即利用“形状”而非“纹理”来区分肢体与背景。

------

## 3. Geo-Sapiens 框架方法论

### 3.1 核心设计理念

Geo-Sapiens 的核心理念是将 Sim-to-Real 适应过程建模为一个**多模态几何共识（Multi-Modal Geometric Consensus）**过程。我们假设：尽管 Sapiens 的姿态估计头（Pose Head）在婴儿数据上可能失效（因为它是语义层面的），但 Sapiens 的深度（Depth Head）和法线（Normal Head）估计头具有更强的跨域鲁棒性。这是因为深度和法线主要依赖于局部的光影着色（Shape-from-Shading）和纹理梯度，这些低层视觉线索在成人和婴儿之间是共享的。

因此，我们设计利用冻结的深度和法线头作为“监督者”，通过物理几何约束来校正姿态头在未标记真实数据上的预测。

### 3.2 总体架构

Geo-Sapiens 框架包含三个阶段：

1. **阶段一：解剖学适配的监督热身（Skeleton-Adapted Supervised Warmup）。** 在合成数据（MINI-RGBD）上训练，使模型适应幼儿的骨骼拓扑结构。
2. **阶段二：几何引导的无监督域适应（Geometry-Guided UDA）。** 在未标记的真实数据（SyRIP-Real）上，利用 Mean-Teacher 架构结合深度和法线一致性损失进行适应。
3. **阶段三：少样本真实域微调（Few-Shot Real Refinement）。** 利用 SyRIP 中极少量的标记真实数据进行最终的参数校准。

### 3.3 阶段一：解剖学适配与合成域热身

#### 3.3.1 关键点映射与解码器重构

Sapiens 预训练模型输出的是 308 个细粒度关键点，而 MINI-RGBD 数据集基于 SMIL 模型，通常包含 25 个关键点 2。首先，我们需要构建一个映射函数 $\mathcal{M}_{keypoint}$，将目标任务所需的关键点（如 COCO 17点或 SMIL 25点）与 Sapiens 的编码器特征对齐。

- **解码器设计：** 我们摒弃 Sapiens 原有的庞大解码器，初始化一个轻量级的 **Deconvolutional Head**（类似于 SimpleBaseline 的头部结构）。这不仅能防止在小规模数据集上过拟合，还能保持推理的高效性。
- **输入分辨率：** 保持 $1024 \times 1024$ 的高分辨率输入，以充分利用 Sapiens 编码器对细微纹理的捕捉能力。

#### 3.3.2 弹性尺度增强（Elastic Scale Augmentation）

为了缓解从成人到婴儿的“解剖学漂移”，我们在合成数据训练中引入一种特殊的**弹性尺度增强**策略。

- **原理：** 通过非线性扭曲（Non-linear Warping），随机改变合成图像中肢体的长宽比和头身比。我们不仅使用标准的 MINI-RGBD 图像，还动态生成具有极端比例（更短的腿、更大的头）的增强样本。
- **目的：** 这种增强迫使 Sapiens 编码器适应更广泛的身体比例分布，防止其将真实的婴儿比例视为“异常值”或“噪声”。

### 3.4 阶段二：多模态几何一致性（MMGC）适应机制

这是本方案的核心创新点。在面对无标签的真实数据（SyRIP-Real）时，我们构建了一个增强版的 Mean-Teacher 框架。

#### 3.4.1 基础架构：Mean-Teacher

- **学生网络（Student）：** 接收强增强（Strong Augmentation，如 CutMix, Color Jitter）的真实图像。
- **教师网络（Teacher）：** 权重为学生网络的指数移动平均（EMA）。接收弱增强（Weak Augmentation）图像，生成的伪标签用于监督学生网络。
- **一致性损失（$L_{cons}$）：** 最小化学生预测与教师伪标签之间的差异。

#### 3.4.2 创新模块：几何批评家（Geometric Critics）

我们在训练图中引入两个**冻结**的辅助分支，它们直接加载 Sapiens-1B 的预训练权重：

1. **深度估计器（$\Phi_{depth}$）：** 输出单目相对深度图 $M_{depth}$。
2. **法线估计器（$\Phi_{normal}$）：** 输出表面法线图 $M_{normal}$。

这两个分支在训练过程中不进行梯度更新，仅作为固定的几何参考系。基于此，我们提出两个几何损失函数：

**A. 深度-骨骼一致性损失（$L_{geo-depth}$）**

- **动机：** 在 2D 图像中，婴儿的四肢可能因为透视看起来很短，但在 2.5D 空间（图像坐标 + 相对深度）中，骨骼长度应保持相对稳定。若模型错误地将关键点定位在背景床单上，该点的深度值会发生突变，导致计算出的 2.5D 骨长异常。

- 公式推导：

  对于每一对连接的关节 $(i, j)$（如左膝-左踝），我们查询其在深度图上的值 $d_i, d_j$。定义的 2.5D 距离为：

  

  $$D_{ij} = \sqrt{(u_i - u_j)^2 + (v_i - v_j)^2 + \lambda_{z}(d_i - d_j)^2}$$

  

  由于深度是相对的，我们无法约束绝对长度，但可以约束左右对称性和时间连续性。

  

  $$L_{geo-depth} = \sum_{(l,r) \in SymPairs} | D_{l} - D_{r} |$$

  

  该损失惩罚左右肢体在 2.5D 空间中的显著不对称（除非深度图明确显示遮挡）。

**B. 法线-表面对齐损失（$L_{geo-norm}$）**

- **动机：** 婴儿通常仰卧。特定的解剖关键点（如胸部、腹部）对应的表面法线应大致指向相机方向（Z轴），而侧面关键点（如肩部、髋部外侧）的法线应指向侧方。背景（床单）的法线通常是杂乱或平坦向上的。

- **机制：** 我们为每个关键点 $k$ 定义一个先验法线分布 $\mathcal{N}_{prior}^{(k)}$（通过统计合成数据获得）。

- 损失计算：

  

  $$L_{geo-norm} = \sum_{k} (1 - \cos(\vec{n}_{pred}^{(k)}, \vec{n}_{estimated}))$$

  

  其中 $\vec{n}_{estimated}$ 是 Sapiens 法线头在预测坐标 $(u_k, v_k)$ 处的输出。

- **效果：** 如果模型将“胸部”关键点预测到了身体轮廓之外的褶皱床单上，该处的法线方向极有可能与先验（指向相机）不符，从而产生高额损失，迫使模型将预测拉回身体表面。

#### 3.4.3 幼儿流形正则化（Infant Manifold Prior）

借鉴 SHIFT 4 的思想，我们训练一个轻量级的变分自编码器（VAE）来学习婴儿合法 2D 姿态的低维流形。

- **流形损失（$L_{manifold}$）：** 将学生网络预测的 2D 姿态输入 VAE，计算重构误差。若预测姿态违反了婴儿的生物力学约束（如膝盖反向弯曲），重构误差会很大。这作为一个解剖学约束，防止模型输出畸形姿态。

### 3.5 阶段三：测试时自适应（Test-Time Adaptation, TTA）

在实际部署阶段，为了进一步适应特定临床场景（如不同的摄像机角度或光照），我们采用基于**元优化（Meta-Optimization）**的测试时适应策略 4。

- **机制：** 对于输入的视频流，冻结编码器，仅利用上述的无监督几何损失（$L_{geo-depth}$ 和 $L_{geo-norm}$）对解码器进行几步快速梯度下降。这允许模型针对当前具体的婴儿和环境进行个性化的“微调”，而无需任何标签。

------

## 4. 技术实施细节

### 4.1 数据预处理与增强

| **数据集**          | **用途**                | **预处理操作**                                         |
| ------------------- | ----------------------- | ------------------------------------------------------ |
| **MINI-RGBD**       | 源域训练 (Source)       | 调整至 1024x1024; 弹性尺度增强; Cut-Occlude (模拟遮挡) |
| **SyRIP-Synth**     | 源域训练 (Source)       | 同上; 混合入 MINI-RGBD 以增加多样性                    |
| **SyRIP-Real**      | 目标域适应 (Unlabeled)  | 强/弱增强对生成 (Strong/Weak Augmentation Generation)  |
| **SyRIP-Real (GT)** | 验证与测试 (Validation) | 仅调整尺寸; 用于计算 mAP 和 PCK                        |

Cut-Occlude 增强策略 4：

为了模拟真实场景中常见的被子、玩具遮挡，我们在训练过程中随机将纹理补丁（Texture Patches）粘贴到婴儿图像的关键部位。这迫使 Sapiens 学习利用全局上下文（如身体其余部分的几何结构）来推断被遮挡关键点的位置，而不是仅仅依赖局部纹理。

### 4.2 模型配置

- **骨干网络（Backbone）：** Sapiens-0.6B。选择 0.6B 而非 2B 是为了在学术级计算资源下平衡训练效率与性能。Sapiens-0.6B 已具备足够的几何表征能力。
- **输入尺寸：** $1024 \times 1024$ 像素。
- **优化器：** AdamW。
  - Encoder LR: $1 \times 10^{-5}$ (低学习率，防止遗忘)。
  - Decoder LR: $1 \times 10^{-3}$ (高学习率，快速适应)。
- **损失权重：** $\lambda_{sup}=1.0, \lambda_{cons}=1.0, \lambda_{geo}=0.1, \lambda_{manifold}=0.05$。几何损失作为正则项，权重较低以避免训练初期不稳定。

### 4.3 训练流程控制

采用分步式训练策略以确保稳定性：

1. **Warmup (Epoch 0-20):** 仅使用 $\mathcal{L}_{sup}$ 在合成数据上训练。此时几何损失关闭。
2. **Adaptation (Epoch 21-50):** 引入无标签真实数据，开启 $\mathcal{L}_{cons}$ 和 $\mathcal{L}_{manifold}$。
3. **Geometric Refinement (Epoch 51-80):** 开启 $\mathcal{L}_{geo-depth}$ 和 $\mathcal{L}_{geo-norm}$。此时模型已具备基本的姿态估计能力，几何损失开始修正细微的漂移和背景误检。

------

## 5. 预期性能评估与对比分析

### 5.1 评价指标

- **PCK@0.05 (Percentage of Correct Keypoints):** 标准化距离误差小于头部尺寸 5% 的关键点比例。这是衡量精度的核心指标。
- **G-Error (Geometric Consistency Error):** 我们提出的新指标，用于衡量同一肢体在视频序列中长度方差的稳定性。方差越小，表明模型对刚体运动的理解越好。
- **Sim-to-Real Gap Reduction:** (Real_Acc_Ours - Real_Acc_Baseline) / (Real_Acc_Oracle - Real_Acc_Baseline)。衡量我们缩小了多少合成与真实之间的差距。

### 5.2 对比基线 (Baselines)

| **方法**                                  | **核心机制**                   | **预期劣势**                                                 |
| ----------------------------------------- | ------------------------------ | ------------------------------------------------------------ |
| **OpenPose / ViTPose (Adult-Pretrained)** | 直接推理                       | 由于解剖学结构差异（头身比），在婴儿数据上 PCK 极低，容易漏检四肢。 |
| FiDIP 5                                   | 对抗性域适应 (GANs)            | 关注纹理风格迁移，容易在几何结构上产生伪影（Artifacts），导致关键点漂移。 |
| SHIFT 4                                   | Mean-Teacher + 流形先验        | 缺乏图像层面的几何约束。依靠分割掩码（Segmentation）只能处理轮廓，无法处理肢体在躯干上的重叠（Self-occlusion）。 |
| **Geo-Sapiens (Ours)**                    | **Sapiens + 多模态几何一致性** | **利用深度和法线直接约束 3D 物理合理性，解决自遮挡和背景混淆问题，预期性能最优。** |



### 5.3 预期结果分析

我们预计 Geo-Sapiens 在 SyRIP-Real 测试集上的 PCK@0.05 将超过 SHIFT 方法 **5-8个百分点**。

- **主要收益来源：** Sapiens 的 1K 高分辨率特征将显著提升对手腕、脚踝等小目标的检测率；法线一致性损失将大幅减少将床单褶皱误检为肢体的情况。
- **消融实验预期：** 移除深度或法线损失后，预计在复杂背景下的误检率会上升；移除弹性尺度增强后，预计四肢末端的回归精度会下降。

------

## 6. 讨论与局限性

### 6.1 方案的高创新性总结

Geo-Sapiens 不仅仅是一个微调方案，它代表了一种**利用基础模型的多任务一致性进行自监督**的新范式。

1. **反向利用 Sapiens：** 通常人们使用 Sapiens 的 Pose 头做 Pose。我们创新地使用 Sapiens 的 Depth/Normal 头来*修正* Pose 头。这种“以子之矛，攻子之盾”的策略充分挖掘了基础模型的隐含知识。
2. **物理感知的无监督学习：** 将损失函数构建在 3D 几何（法线、深度）之上，而非仅仅是 2D 像素或语义标签。这使得模型在没有真实标签的情况下，依然受到物理规律的约束。

### 6.2 潜在局限性

- **计算开销：** 同时运行 Sapiens 的 Pose、Depth 和 Normal 头需要巨大的显存。在训练阶段这不是问题（可以使用梯度累积），但在推理阶段，为了实时性，我们可能需要蒸馏一个轻量级的单头模型。
- **相对深度的歧义：** Sapiens 输出的是相对深度。虽然我们设计了基于比率的损失函数来规避绝对尺度问题，但在极端视角下，相对深度的不稳定性仍可能引入噪声。

### 6.3 伦理与数据隐私

本方案严格遵守数据隐私原则。所有真实数据（SyRIP）均在无监督或少样本设置下使用，且不需要将真实数据上传至云端进行大规模标注。Geo-Sapiens 的 TTA（测试时适应）特性甚至允许模型在本地终端（如医院的边缘设备）上针对特定患者进行在线优化，无需数据出院，极大地保护了患者隐私。

------

## 7. 结论

针对 MINI-RGBD 和 SyRIP 数据集及其背后的临床需求，本报告提出了 **Geo-Sapiens** 框架。通过深度融合 Meta Sapiens 基础模型的强大表征能力与创新的多模态几何一致性机制，我们成功构建了一条从合成数据通往真实世界的高保真路径。该方案不仅在技术上解决了 Sim-to-Real 的核心痛点——域漂移与解剖学不匹配，更在临床应用层面，为实现全自动、非侵入式的婴儿神经发育评估提供了坚实的技术底座。Geo-Sapiens 证明了在数据稀缺的医疗垂直领域，利用通用基础模型的跨模态几何知识是实现高性能 AI 的关键钥匙。

------

**(正文结束，以下为补充信息表格)**

### 附录 A: Geo-Sapiens 损失函数详细定义

| **损失项**         | **符号**                  | **定义/公式描述**                           | **作用域**                                 | **权重 (λ)** |
| ------------------ | ------------------------- | ------------------------------------------- | ------------------------------------------ | ------------ |
| **有监督热图损失** | $\mathcal{L}_{sup}$       | $MSE(\hat{H}_s, H_{gt})$                    | 源域 (Synthetic)                           | 1.0          |
| **一致性损失**     | $\mathcal{L}_{cons}$      | $MSE(\hat{H}_{student}, \hat{H}_{teacher})$ | 目标域 (Real)                              | 1.0          |
| **深度一致性损失** | $\mathcal{L}_{geo-depth}$ | $\sum                                       | Ratio_{2.5D}^{left} - Ratio_{2.5D}^{right} | $            |
| **法线对齐损失**   | $\mathcal{L}_{geo-norm}$  | $1 - \cos(\vec{n}_{pred}, \vec{n}_{prior})$ | 目标域 (Real)                              | 0.1          |
| **流形正则化**     | $\mathcal{L}_{manifold}$  | $                                           |                                            | P - VAE(P)   |

### 附录 B: 数据集统计与使用策略

| **数据集**        | **图片数量** | **来源**           | **在 Geo-Sapiens 中的角色**                                  |
| ----------------- | ------------ | ------------------ | ------------------------------------------------------------ |
| **MINI-RGBD**     | 12,000       | 合成 (SMIL)        | **有监督训练基石**。用于学习婴儿骨骼拓扑和基础姿态特征。     |
| **SyRIP (Synth)** | 1,000        | 合成 (SMIL)        | **辅助源域**。与 MINI-RGBD 合并以增加多样性。                |
| **SyRIP (Real)**  | ~700         | 真实拍摄           | **无监督目标域 & 验证**。不使用标签进行 UDA 训练；仅使用少量标签进行最终评估。 |
| **Humans-300M**   | 300M         | 真实 (In-the-wild) | **预训练知识库**。Sapiens 权重的来源，提供了通用的 Depth/Normal/Pose 特征。 |